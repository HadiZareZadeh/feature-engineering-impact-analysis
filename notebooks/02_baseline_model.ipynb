{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Model: Minimal Preprocessing\n",
        "\n",
        "This notebook establishes a baseline by training a model with minimal preprocessing to compare against feature-engineered versions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "with open('../adult_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "X_train = data['X_train']\n",
        "X_test = data['X_test']\n",
        "y_train = data['y_train']\n",
        "y_test = data['y_test']\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "# Check target variable distribution\n",
        "print(f\"\\nTarget variable type: {type(y_train)}\")\n",
        "print(f\"y_train unique values: {y_train.unique()}\")\n",
        "print(f\"y_train value counts:\\n{y_train.value_counts()}\")\n",
        "print(f\"\\ny_test unique values: {y_test.unique()}\")\n",
        "print(f\"y_test value counts:\\n{y_test.value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure target variable is properly formatted\n",
        "# Convert to numpy array if it's a pandas Series\n",
        "if hasattr(y_train, 'values'):\n",
        "    y_train = y_train.values\n",
        "if hasattr(y_test, 'values'):\n",
        "    y_test = y_test.values\n",
        "\n",
        "# Check if target needs to be re-encoded\n",
        "unique_train = np.unique(y_train)\n",
        "if len(unique_train) < 2:\n",
        "    print(\"WARNING: y_train has only one class. Attempting to fix...\")\n",
        "    print(f\"Current y_train unique values: {unique_train}\")\n",
        "    \n",
        "    # Try to reload original data and recreate target\n",
        "    print(\"\\nReloading original data to recreate target variable...\")\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "    columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
        "               'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "               'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "    \n",
        "    df_original = pd.read_csv(url, names=columns, na_values=' ?', skipinitialspace=True)\n",
        "    df_original['income_binary'] = df_original['income'].str.strip().str.contains('>50K', regex=False).astype(int)\n",
        "    df_original_clean = df_original.dropna()\n",
        "    \n",
        "    # Recreate the split with the same random state\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_original = df_original_clean.drop(['income', 'income_binary'], axis=1)\n",
        "    y_original = df_original_clean['income_binary']\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_original, y_original, test_size=0.2, random_state=42, stratify=y_original\n",
        "    )\n",
        "    \n",
        "    # Convert to numpy arrays\n",
        "    if hasattr(y_train, 'values'):\n",
        "        y_train = y_train.values\n",
        "    if hasattr(y_test, 'values'):\n",
        "        y_test = y_test.values\n",
        "    \n",
        "    print(f\"Fixed! y_train now has {len(np.unique(y_train))} classes: {np.unique(y_train)}\")\n",
        "    print(f\"y_train distribution: {np.bincount(y_train)}\")\n",
        "else:\n",
        "    print(f\"✓ Target variable is correctly formatted with {len(unique_train)} classes: {unique_train}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline: Minimal Preprocessing\n",
        "\n",
        "For the baseline, we'll use:\n",
        "- Simple label encoding for categorical variables\n",
        "- No scaling\n",
        "- No feature engineering\n",
        "- Basic logistic regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate numerical and categorical columns\n",
        "numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f\"Numerical columns: {numerical_cols}\")\n",
        "print(f\"Categorical columns: {categorical_cols}\")\n",
        "\n",
        "# Simple label encoding for categorical variables\n",
        "X_train_encoded = X_train.copy()\n",
        "X_test_encoded = X_test.copy()\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_train_encoded[col] = le.fit_transform(X_train[col].astype(str))\n",
        "    X_test_encoded[col] = le.transform(X_test[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(\"\\nBaseline preprocessing complete: Label encoding only\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train baseline model\n",
        "baseline_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "baseline_model.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_baseline = baseline_model.predict(X_test_encoded)\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "\n",
        "print(f\"Baseline Model Accuracy: {baseline_accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_baseline))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['≤50K', '>50K'],\n",
        "            yticklabels=['≤50K', '>50K'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(f'Baseline Model Confusion Matrix\\nAccuracy: {baseline_accuracy:.4f}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save baseline results\n",
        "baseline_results = {\n",
        "    'accuracy': baseline_accuracy,\n",
        "    'model': baseline_model,\n",
        "    'label_encoders': label_encoders\n",
        "}\n",
        "\n",
        "with open('../baseline_results.pkl', 'wb') as f:\n",
        "    pickle.dump(baseline_results, f)\n",
        "\n",
        "print(\"Baseline results saved to '../baseline_results.pkl'\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
