{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration: UCI Adult Income Dataset\n",
        "\n",
        "## Overview\n",
        "\n",
        "The Adult Income dataset predicts whether income exceeds $50K/year based on census data. This is a binary classification problem with mixed data types, making it perfect for demonstrating feature engineering techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "\n",
        "# Load dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', \n",
        "           'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "df = pd.read_csv(url, names=columns, na_values=' ?', skipinitialspace=True)\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset info\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n",
        "print(\"\\nCategorical columns:\")\n",
        "print(df.select_dtypes(include=['object']).columns.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Target distribution\n",
        "print(\"Target distribution:\")\n",
        "print(df['income'].value_counts())\n",
        "print(f\"\\nTarget distribution (%):\")\n",
        "print(df['income'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(8, 5))\n",
        "df['income'].value_counts().plot(kind='bar', color=['steelblue', 'coral'])\n",
        "plt.xlabel('Income')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Target Distribution')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare target variable\n",
        "# Check unique income values first\n",
        "print(\"Unique income values:\", df['income'].unique())\n",
        "print(\"Income value counts:\\n\", df['income'].value_counts())\n",
        "\n",
        "# Create binary target: 1 if income > 50K, 0 otherwise\n",
        "# Handle both '>50K' and ' >50K' formats (with or without leading space)\n",
        "df['income_binary'] = df['income'].str.strip().str.contains('>50K', regex=False).astype(int)\n",
        "\n",
        "# Verify target distribution\n",
        "print(\"\\nTarget variable distribution:\")\n",
        "print(df['income_binary'].value_counts())\n",
        "print(f\"\\nTarget distribution (%):\")\n",
        "print(df['income_binary'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Save preprocessed data\n",
        "import pickle\n",
        "\n",
        "# Handle missing values (simple strategy: drop for now, can be improved)\n",
        "df_clean = df.dropna()\n",
        "\n",
        "# Split data\n",
        "X = df_clean.drop(['income', 'income_binary'], axis=1)\n",
        "y = df_clean['income_binary']\n",
        "\n",
        "# Verify y has both classes before splitting\n",
        "print(f\"\\nBefore split - y unique values: {y.unique()}\")\n",
        "print(f\"Before split - y value counts:\\n{y.value_counts()}\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Verify after split\n",
        "print(f\"\\nAfter split - y_train unique values: {y_train.unique()}\")\n",
        "print(f\"After split - y_train value counts:\\n{y_train.value_counts()}\")\n",
        "print(f\"\\nAfter split - y_test unique values: {y_test.unique()}\")\n",
        "print(f\"After split - y_test value counts:\\n{y_test.value_counts()}\")\n",
        "\n",
        "data_dict = {\n",
        "    'X_train': X_train,\n",
        "    'X_test': X_test,\n",
        "    'y_train': y_train,\n",
        "    'y_test': y_test\n",
        "}\n",
        "\n",
        "with open('../adult_data.pkl', 'wb') as f:\n",
        "    pickle.dump(data_dict, f)\n",
        "\n",
        "print(f\"\\nTraining set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(\"Data saved to '../adult_data.pkl'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
